{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.subplots()\n",
    "# hack to remove hide globally installed libraries, which are the wrong R version\n",
    "from rpy2 import robjects as ro\n",
    "ro.r(\".libPaths('/local/scratch/gt/lib/R/library')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsbids import BidsLayout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.polynomial import Polynomial\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import scipy.stats as scs\n",
    "import more_itertools as itx\n",
    "import itertools as it\n",
    "import xarray as xr\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from lib.bidsarray import layout_map\n",
    "from lib.plotting import move_legend_fig_to_ax, fig_to_numpy, annotate_axes\n",
    "from pathlib import Path\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.ticker import FuncFormatter, FormatStrFormatter\n",
    "import templateflow.api as tflow\n",
    "import nibabel as nb\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import graph_tool.all as gt\n",
    "import colormaps as cmaps\n",
    "from lib.dataset import Dataset\n",
    "from lib.bidsarray import layout_map\n",
    "from lib.plotting import comparison_plot, add_colorbar, plot_hierachical_connectome\n",
    "from dask.diagnostics import ProgressBar\n",
    "from lib.seaborn_stats import MLEFit, Lme4CI, PolyCI, PearsonrAnnot\n",
    "from lib import atlases\n",
    "from lib.utils import concat_product\n",
    "\n",
    "from styles import styles as Styles\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# plt.switch_backend(\"cairo\")\n",
    "plt.style.use(\"styles/manuscript.mplstyle\")\n",
    "so.Plot.config.theme.update(plt.rcParams)\n",
    "font_dirs = [Path.home() / \".fonts\"]\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "\n",
    "for font_file in font_files:\n",
    "    font_manager.fontManager.addfont(font_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "from rpy2 import robjects as ro\n",
    "import rpy2.ipython.html\n",
    "rpy2.ipython.html.init_printing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "rutils = importr(\"utils\")\n",
    "rbase = importr(\"base\")\n",
    "lme4 = importr(\"lme4\")\n",
    "rstats = importr(\"stats\")\n",
    "pbkrtest = importr(\"pbkrtest\")\n",
    "lmertest = importr(\"lmerTest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhp = (\n",
    "    Dataset(\".jhp.layout\", \"jhp\", group_label=\"group\")\n",
    "    .add_phenotypes(\"jhp_metadata.yaml\")\n",
    "    .filter(\n",
    "        ~pl.col(\"dx\").is_in([\"BPADI\", \"MDD\", \"Substance_induced\", \"Others\"]),\n",
    "        # ~pl.col(\"subject\").is_in([\"1018\", \"1026\", \"1047\", \"2041\"]),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "topsy = (\n",
    "    Dataset(\".topsy.layout\", \"topsy\")\n",
    "    .add_phenotypes(\"topsy_metadata.yaml\")\n",
    "    .filter(pl.col(\"ddx\").is_in([1, 2, 3, 9, 10]))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "JHP_SESSIONS = {1: \"Baseline\", 2: \"1yr\", 3: \"2yr\", 4: \"3yr\"}\n",
    "TOPSY_SESSIONS = {1: \"Baseline\", 2: \"â‰ˆ6 mo\", 3: \"1-2 yr\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sessions = pl.col(\"session\").unique().len().over(\"subject\")\n",
    "\n",
    "\n",
    "def do_fit(struct):\n",
    "    struct = struct.struct.unnest().filter(pl.all_horizontal(~pl.col(\"*\").is_null()))\n",
    "    if struct[\"x\"].len() == 1:\n",
    "        coefs = [0.0, 0.0]\n",
    "    else:\n",
    "        coefs = Polynomial.fit(struct[\"x\"], struct[\"y\"], 1).convert().coef\n",
    "        if coefs.shape[0] == 1:\n",
    "            coefs = [coefs[0], 0.0]\n",
    "    return {\n",
    "        \"intercept\": (coefs[0]),\n",
    "        \"slope\": (coefs[1]),\n",
    "    }\n",
    "\n",
    "\n",
    "def sel_fit(col):\n",
    "    return (\n",
    "        pl.when(pl.len() > 1)\n",
    "        .then(\n",
    "            pl.struct(pl.col(\"session\").cast(int) - 1, col)\n",
    "            .struct.rename_fields([\"x\", \"y\"])\n",
    "            .map_elements(\n",
    "                do_fit,\n",
    "                return_dtype=pl.Struct({\"intercept\": pl.Float64, \"slope\": pl.Float64}),\n",
    "            )\n",
    "            .struct.rename_fields([f\"{col}_intercept\", f\"{col}_slope\"])\n",
    "        )\n",
    "        .alias(f\"{col}_fit\")\n",
    "    )\n",
    "\n",
    "\n",
    "def sel_recovery(col):\n",
    "    return (pl.col(col).filter(pl.col(\"session\") == \"2\").first() < 4).name.suffix(\n",
    "        \"_recovery\"\n",
    "    )\n",
    "\n",
    "def sel_start_zero(col):\n",
    "    return (pl.col(col).filter(pl.col(\"session\") == \"1\").first() < 4).name.suffix(\n",
    "        \"_nostart\"\n",
    "    )\n",
    "\n",
    "\n",
    "jhp_hx = (\n",
    "    jhp.metadata.filter(pl.col(\"group\") == \"Patient\")\n",
    "    .group_by(\"subject\")\n",
    "    .agg(\n",
    "        pl.len().alias(\"num_sessions\"),\n",
    "        pl.first(\"sex\"),\n",
    "        pl.mean(\"age\"),\n",
    "        pl.mean(\"sans\", \"saps\").name.suffix(\"_mean\"),\n",
    "        pl.col(\"saps\", \"sans\").filter(pl.col(\"session\") == \"1\").first()\n",
    "        .name.suffix(\"_baseline\"),\n",
    "        sel_fit(\"sans\"),\n",
    "        sel_fit(\"saps\"),\n",
    "    )\n",
    "    .unnest(\"sans_fit\", \"saps_fit\")\n",
    ")\n",
    "\n",
    "topsy_hx = (\n",
    "    topsy.metadata.filter(pl.col(\"group\") == \"FEP\", pl.col(\"session\").cast(int) < 3)\n",
    "    .group_by(\"subject\")\n",
    "    .agg(\n",
    "        pl.len().alias(\"num_sessions\"),\n",
    "        pl.first(\"sex\"),\n",
    "        pl.mean(\"age\"),\n",
    "        pl.mean(\"PANSSP\", \"PANSSN\", \"SOFAS\").name.suffix(\"_mean\"),\n",
    "        pl.col(\"PANSSP\", \"PANSSN\", \"SOFAS\").filter(pl.col(\"session\") == \"1\").first()\n",
    "        .name.suffix(\"_baseline\"),\n",
    "        sel_fit(\"PANSSP\"),\n",
    "        sel_fit(\"PANSSN\"),\n",
    "        sel_fit(\"SOFAS\"),\n",
    "        sel_recovery(\"PANSSP\"),\n",
    "        sel_recovery(\"PANSSN\"),\n",
    "        sel_start_zero(\"PANSSN\"),\n",
    "    )\n",
    "    .unnest(cs.matches(\".*_fit\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = (\n",
    "    topsy_hx.filter(pl.col(\"num_sessions\") > 1)\n",
    "    .group_by(\"sex\", \"PANSSN_recovery\")\n",
    "    .len()\n",
    "    .pivot(index=\"sex\", columns=\"PANSSN_recovery\", values=\"len\")\n",
    "    .drop(\"sex\")\n",
    "    .to_numpy()\n",
    ")\n",
    "scs.chi2_contingency(table)\n",
    "\n",
    "lm = smf.ols(\n",
    "    \"age ~ PANSSN_recovery\",\n",
    "    data=topsy_hx.filter(pl.col(\"num_sessions\") > 1).with_columns(\n",
    "        pl.col(\"PANSSN_recovery\").cast(int)\n",
    "    ),\n",
    ").fit()\n",
    "lm.model.exog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographics and clinical scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 10), layout=\"constrained\")\n",
    "axs = fig.subplots(6, 2)\n",
    "for i, x in enumerate((\"PANSSP_recovery\", \"PANSSN_recovery\")):\n",
    "    comparison_plot(\n",
    "        topsy_hx.filter(pl.col(\"num_sessions\") > 1).to_pandas(),\n",
    "        y=\"age\",\n",
    "        x=x,\n",
    "        ax=axs[0, i],\n",
    "        xlabel=\"Recovery?\",\n",
    "        ylabel=\"Age\",\n",
    "    )\n",
    "for i, x in enumerate((\"PANSSP_recovery\", \"PANSSN_recovery\")):\n",
    "    (\n",
    "        so.Plot(\n",
    "            topsy_hx.filter(pl.col(\"num_sessions\") > 1).to_pandas(),\n",
    "            color=\"sex\",\n",
    "            x=x,\n",
    "\n",
    "        )\n",
    "        .add(so.Bar(), so.Hist())\n",
    "        .on(axs[1, i])\n",
    "        .plot()\n",
    "    )\n",
    "for i, y in enumerate((\"PANSSP_slope\", \"PANSSN_slope\")):\n",
    "    (\n",
    "        so.Plot(\n",
    "            topsy_hx.filter(pl.col(\"num_sessions\") > 1).to_pandas(),\n",
    "            y=y,\n",
    "            x=\"age\",\n",
    "\n",
    "        )\n",
    "        .add(so.Dot())\n",
    "        .on(axs[2, i])\n",
    "        .plot()\n",
    "    )\n",
    "for i, y in enumerate((\"PANSSP_slope\", \"PANSSN_slope\")):\n",
    "    comparison_plot(\n",
    "        topsy_hx.filter(pl.col(\"num_sessions\") > 1).to_pandas(),\n",
    "        x=\"sex\",\n",
    "        y=y,\n",
    "        ax=axs[3, i],\n",
    "        xlabel=\"Sex\",\n",
    "    )\n",
    "\n",
    "for i, y in enumerate((\"PANSSP_intercept\", \"PANSSN_intercept\")):\n",
    "    (\n",
    "        so.Plot(\n",
    "            topsy_hx.filter(pl.col(\"num_sessions\") > 1).to_pandas(),\n",
    "            y=y,\n",
    "            x=\"age\",\n",
    "\n",
    "        )\n",
    "        .add(so.Dot())\n",
    "        .on(axs[4, i])\n",
    "        .plot()\n",
    "    )\n",
    "for i, y in enumerate((\"PANSSP_intercept\", \"PANSSN_intercept\")):\n",
    "    comparison_plot(\n",
    "        topsy_hx.filter(pl.col(\"num_sessions\") > 1).to_pandas(),\n",
    "        x=\"sex\",\n",
    "        y=y,\n",
    "        ax=axs[5, i],\n",
    "        xlabel=\"Sex\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinical Score Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sessions = pl.col(\"session\").unique().len().over(\"subject\")\n",
    "topsy_df = (\n",
    "    topsy.metadata.with_columns(pl.col.session.cast(int))\n",
    "    .filter(\n",
    "        pl.col(\"group\") == \"FEP\",\n",
    "        num_sessions > 1,\n",
    "        ~pl.col(\"PANSSP\", \"PANSSN\").is_null(),\n",
    "        pl.col.session < 3,\n",
    "    )\n",
    "    .to_pandas()\n",
    ")\n",
    "jhp_df = (\n",
    "    jhp.metadata.with_columns(pl.col.session.cast(int))\n",
    "    .filter(\n",
    "        pl.col(\"group\") == \"Patient\",\n",
    "        num_sessions > 1,\n",
    "        ~pl.col(\"saps\", \"sans\").is_null(),\n",
    "    )\n",
    "    .to_pandas()\n",
    ")\n",
    "with (ro.default_converter + ro.pandas2ri.converter).context():\n",
    "#     lm1 = lme4.lmer(\"PANSSP ~ (1|subject)\", data=topsy_df)\n",
    "#     lm2 = lme4.lmer(\"PANSSP ~ session + (1|subject)\", data=topsy_df)\n",
    "#     res = pbkrtest.PBmodcomp(lm2, lm1)\n",
    "#     print(res[\"test\"])\n",
    "    lm1 = lme4.lmer(\"saps ~ session + (1|subject)\", data=jhp_df)\n",
    "    lm2 = lme4.lmer(\"sans ~ session + (session|subject)\", data=jhp_df)\n",
    "    res = pbkrtest.PBmodcomp(lm2, lm1)\n",
    "    # print(res[\"test\"])\n",
    "    res = lmertest.ranova(lm2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with (ro.default_converter + ro.pandas2ri.converter).context():\n",
    "    res = lmertest.ranova(lm2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lme4.ranova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (ro.default_converter + ro.pandas2ri.converter).context():\n",
    "\n",
    "    print(ro.r(\"summary\")(lm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| test: foo\n",
    "\n",
    "#| hello: world\n",
    "jitter = so.Jitter(width=0.2, seed=1)\n",
    "fig = plt.figure(figsize=(8, 5), layout=\"constrained\")\n",
    "\n",
    "axs = fig.subplots(2, 2)\n",
    "\n",
    "variables = np.array([[\"PANSSP\", \"saps\"], [\"PANSSN\", \"sans\"]])\n",
    "datasets = [\n",
    "    topsy.metadata.filter(pl.col(\"group\") == \"FEP\", pl.col(\"session\").cast(int) < 3),\n",
    "    jhp.metadata.filter(pl.col(\"group\") == \"Patient\"),\n",
    "]\n",
    "ses_labels = [TOPSY_SESSIONS, JHP_SESSIONS]\n",
    "\n",
    "labels = {\n",
    "    \"PANSSP\": \"PANSS8-P\",\n",
    "    \"PANSSN\": \"PANSS8-N\",\n",
    "    \"sans\": \"SANS\",\n",
    "    \"saps\": \"SAPS\",\n",
    "}\n",
    "formulae = [\"y ~ x + (1|group)\", \"y ~ x + (x|group)\"]\n",
    "\n",
    "for x, y in np.ndindex(2, 2):\n",
    "    variable = variables[x, y]\n",
    "    label = labels[variable]\n",
    "    dataset = datasets[y]\n",
    "    ax = axs[x, y]\n",
    "    num_sessions = pl.col(\"session\").unique().len().over(\"subject\")\n",
    "    (\n",
    "        so.Plot(\n",
    "            dataset.with_columns(\n",
    "                pl.col(\"session\").cast(int),#.replace(jhp_sessions),\n",
    "                pl.when(num_sessions > 1).then(pl.col(variable)).name.prefix(\"multi_\"),\n",
    "                pl.when(num_sessions == 1)\n",
    "                .then(pl.col(variable))\n",
    "                .name.prefix(\"single_\"),\n",
    "            ).to_pandas(),\n",
    "            x=\"session\",\n",
    "            y=f\"multi_{variable}\",\n",
    "            group=\"subject\",\n",
    "        )\n",
    "        .add(\n",
    "            so.Line(color=\"#555555\", linestyle=\"dashed\", linewidth=1, alpha=0.3), jitter\n",
    "        )\n",
    "        .add(so.Line(linewidth=2), MLEFit())\n",
    "        .add(so.Band(alpha=0.4), Lme4CI(formula=formulae[y], nsims=500))\n",
    "        .add(so.Dot(color=\"#333333\", edgewidth=0, alpha=0.5), jitter)\n",
    "        .add(\n",
    "            so.Dot(color=\"#333333\", fill=False, alpha=0.8),\n",
    "            so.Shift(x=-0.3),\n",
    "            so.Jitter(width=0.2, seed=5),\n",
    "            y=f\"single_{variable}\",\n",
    "        )\n",
    "        .scale(\n",
    "            x=so.Continuous().tick(at=[1,2,3,4]).label(like=ses_labels[y].get),\n",
    "            y=so.Continuous().tick(every=4),\n",
    "        )\n",
    "        .label(y=label, x=\"Session\")\n",
    "        .on(ax)\n",
    "        .plot()\n",
    "    )\n",
    "\n",
    "axs[0, 0].set_title(\"TOPSY\", **Styles.col_title)\n",
    "axs[0, 1].set_title(\"JHP\", **Styles.col_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-hx\n",
    "cell-offset: -1\n",
    "\n",
    "---\n",
    "Baseline and follow-up clinical scores in early schizophrenia patients. At baseline, empty circles show subjects with no follow-ups. Filled circles connected by a line represent the same subject across multiple visits. No significant differences in scores were found between subjects with and without follow-up visits. Trendlines show a linear fixed effect model of parameter against session with random slopes and intercepts fit for every subject (only random intercepts for TOPSY). Shaded bands show a 95% CI computed with parametric bootstrapping resampling residuals and random effects 500 times. In the TOPSY dataset, the PANSS8-P score was significantly lower in the second session than the first (1000 perms, p < .001). No other symptom scores significantly changed across session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather white matter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wm_from_rois(path, wildcards, atlases):\n",
    "    labels = list(\n",
    "        it.chain.from_iterable(\n",
    "            zip(it.repeat(i), range(np.max(atlas).astype(int) + 1))\n",
    "            for i, atlas in enumerate(atlases)\n",
    "        )\n",
    "    )\n",
    "    nlabels = len(labels)\n",
    "\n",
    "    @layout_map(parallel=True, dims={\"roi\": nlabels}, dtype=float)\n",
    "    def inner(path):\n",
    "        data = nb.load(path).get_fdata()\n",
    "        result = np.empty((nlabels,))\n",
    "        try:\n",
    "            for i in range(0, nlabels):\n",
    "                atlas_ix, ix = labels[i]\n",
    "                if ix == 0:\n",
    "                    result[i] = 0\n",
    "                    continue\n",
    "                atlas = atlases[atlas_ix]\n",
    "\n",
    "                result[i] = np.mean(data[atlas == ix])\n",
    "            return result\n",
    "        except:\n",
    "            print(path)\n",
    "            raise\n",
    "\n",
    "    return inner(path, wildcards)\n",
    "\n",
    "\n",
    "def run_roi_sampling(layout, jhu_atlas, lobe_atlas, skeleton_dims):\n",
    "    mean_skeleton = np.asanyarray(\n",
    "        layout_map(parallel=True, dims=skeleton_dims, dtype=float)(\n",
    "            lambda p: nb.load(p).get_fdata()\n",
    "        )(layout.get(suffix=\"skeletonized\", desc=\"FA\"), [\"subject\", \"session\"]).mean(\n",
    "            [\"subject\", \"session\"]\n",
    "        )\n",
    "        > 0\n",
    "    )\n",
    "    jhu_atlas, lobe_atlas = (\n",
    "        np.where(mean_skeleton, nb.load(atlas).get_fdata(), 0)\n",
    "        for atlas in (jhu_atlas, lobe_atlas)\n",
    "    )\n",
    "    lobe_mask = np.where(jhu_atlas == 0, lobe_atlas, 0)\n",
    "    return get_wm_from_rois(\n",
    "        layout.get(suffix=\"skeletonized\", desc=[\"FA\", \"MD\", \"RD\", \"L1\"]),\n",
    "        [\"subject\", \"session\", \"desc\"],\n",
    "        atlases=[lobe_mask, jhu_atlas],\n",
    "    )\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "topsy_wm_sampled = run_roi_sampling(\n",
    "    topsy.layout.get(suffix=\"skeletonized\"),\n",
    "    jhu_atlas=\"../topsy/code/jhp-atlas/atlas.nii.gz\",\n",
    "    lobe_atlas=\"../topsy/code/jhp-atlas/lobe-atlas.nii.gz\",\n",
    "    skeleton_dims={\"x\": 78, \"y\": 109, \"z\": 79}\n",
    ")\n",
    "jhp_wm_sampled = run_roi_sampling(\n",
    "    jhp.layout.get(suffix=\"skeletonized\"),\n",
    "    jhu_atlas=\"../jhp/derivatives/atlases/atlas.nii.gz\",\n",
    "    lobe_atlas=\"../jhp/derivatives/atlases/lobe-atlas.nii.gz\",\n",
    "    skeleton_dims={\"x\": 248, \"y\": 295, \"z\": 93}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with ProgressBar():\n",
    "    topsy_wm_sampled.to_netcdf(\"topsy_wm_sampled.nc\")\n",
    "    jhp_wm_sampled.to_netcdf(\"jhp_wm_sampled.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all the surface sample files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hems(img):\n",
    "    l = img[img.struc[\"CIFTI_STRUCTURE_CORTEX_LEFT\"]].project(0).flatten()\n",
    "    r = img[img.struc[\"CIFTI_STRUCTURE_CORTEX_RIGHT\"]].project(0).flatten()\n",
    "    return l, r\n",
    "\n",
    "\n",
    "\n",
    "@layout_map(parallel=True, dtype=float, dims={\"vertex\": 64984})\n",
    "def load_data(path):\n",
    "    img = cp.load(path)\n",
    "    lh, rh = get_hems(img)\n",
    "    data = np.full((lh.shape[0] + rh.shape[0]), np.NaN)\n",
    "    bound = lh.shape[0]\n",
    "    data[:bound] = lh\n",
    "    data[bound:] = rh\n",
    "    return data\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "topsy_surface = load_data(\n",
    "    topsy.layout.get(suffix=[\"curv\", \"thickness\"], den=\"32k\"),\n",
    "    [\"subject\", \"session\", \"suffix\"]\n",
    ")\n",
    "jhp_surface = load_data(\n",
    "    jhp.layout.get(suffix=[\"curv\", \"thickness\"], den=\"32k\"),\n",
    "    [\"subject\", \"session\", \"suffix\"],\n",
    ").to_dataset(name=\"surface\")\n",
    "with ProgressBar():\n",
    "    jhp_surface.to_netcdf(\"jhp_surface.nc\")\n",
    "    topsy_surface.to_netcdf(\"topsy_surface.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkmd = pd.read_csv(\"atlas-dkt_labels.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "def do_sampling(ds, layout):\n",
    "\n",
    "    @layout_map(\n",
    "        parallel=True, dims={\"param\": ds[\"param\"], \"roi\": dkmd[\"label\"]}, dtype=float\n",
    "    )\n",
    "    def sample_dk(path):\n",
    "        dknii = cp.load(path)\n",
    "        dkatlas = np.empty(32492 * 2)\n",
    "        dkatlas[:32492] = (\n",
    "            dknii[dknii.struc[\"CIFTI_STRUCTURE_CORTEX_LEFT\"]].project().ravel()\n",
    "        )\n",
    "        dkatlas[32492:] = (\n",
    "            dknii[dknii.struc[\"CIFTI_STRUCTURE_CORTEX_RIGHT\"]].project().ravel()\n",
    "        )\n",
    "        result = np.empty((len(ds[\"param\"]), len(dkmd)))\n",
    "        x = ds.sel(\n",
    "            subject=path.entities[\"subject\"], session=path.entities[\"session\"]\n",
    "        )\n",
    "        for (i, param), (j, label) in it.product(\n",
    "            enumerate(ds[\"param\"]), enumerate(dkmd[\"label\"])\n",
    "        ):\n",
    "            result[i, j] = np.mean(x.sel(param=param)[dkatlas == label])\n",
    "        return result\n",
    "\n",
    "    return (\n",
    "        sample_dk(\n",
    "            layout.get(\n",
    "                suffix=\"dparc\",\n",
    "                subject=ds[\"subject\"].data,\n",
    "                atlas=\"dkt\",\n",
    "                space=\"fsLR\",\n",
    "                den=\"32k\",\n",
    "            ),\n",
    "            wildcards=[\"subject\", \"session\"],\n",
    "        )\n",
    "        .to_dataset(name=\"dk\")\n",
    "        .merge(dkmd.rename(columns={\"label\": \"roi\"}).set_index(\"roi\").to_xarray())\n",
    "    )\n",
    "\n",
    "\n",
    "topsy_surface = xr.open_dataarray(\"topsy_surface.nc\", chunks={})\n",
    "jhp_surface = xr.open_dataarray(\"jhp_surface.nc\", chunks={})\n",
    "topsy_sampled = do_sampling(topsy_surface.rename(suffix=\"param\"), topsy.layout)\n",
    "jhp_sampled = do_sampling(jhp_surface.rename(suffix=\"param\"), jhp.layout)\n",
    "with ProgressBar():\n",
    "    jhp_sampled.to_netcdf(\"jhp_sampled.nc\")\n",
    "    topsy_sampled.to_netcdf(\"topsy_sampled.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topsy_wm_sampled = xr.open_dataarray(\"topsy_wm_sampled.nc\", chunks={})\n",
    "jhp_wm_sampled = xr.open_dataarray(\"jhp_wm_sampled.nc\", chunks={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_md = pl.read_csv(\"atlas-study_labels.csv\")\n",
    "\n",
    "atlas_filters = [\n",
    "    ~pl.col(\"label\").is_in(\n",
    "        [\n",
    "            \"Med\",\n",
    "            \"Po\",\n",
    "            \"Mb\",\n",
    "            \"FTS\",\n",
    "        ]\n",
    "    ),\n",
    "    pl.col(\"group\") != \"cerebellar\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_md.group_by(\"label\").first().filter(atlas_filters).group_by(\"group\").len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_indices = dict(\n",
    "    zip(*atlas_md.filter(pl.col(\"group\").is_in([\"core\", \"global\"]))[[\"name\", \"index\"]])\n",
    ")\n",
    "\n",
    "\n",
    "def get_index(group: str):\n",
    "    return pl.lit(group_indices[group], dtype=pl.Int64)\n",
    "\n",
    "\n",
    "def prepare_wm_rois(df, index):\n",
    "    df = df.join(atlas_md.rename({\"index\": \"roi\"}), on=\"roi\").filter(*atlas_filters)\n",
    "    periph_rois = pl.col(\"group\") == \"peripheral\"\n",
    "    core_rois = pl.col(\"group\").is_in(\n",
    "        [\"projection\", \"callosal\", \"limbic\", \"association\"]\n",
    "    )\n",
    "    return (\n",
    "        pl.concat(\n",
    "            [\n",
    "                df[[*index, \"roi\", \"data\"]],\n",
    "                # # Global\n",
    "                df.group_by(index).agg(\n",
    "                    get_index(\"global\").alias(\"roi\"), pl.mean(\"data\")\n",
    "                ),\n",
    "                # # Core\n",
    "                df.filter(core_rois)\n",
    "                .group_by(index)\n",
    "                .agg(get_index(\"core\").alias(\"roi\"), pl.mean(\"data\")),\n",
    "                # # Peripheral\n",
    "                df.filter(periph_rois)\n",
    "                .group_by(index)\n",
    "                .agg(get_index(\"peripheral\").alias(\"roi\"), pl.mean(\"data\")),\n",
    "                # # Core groups\n",
    "                df.filter(core_rois)\n",
    "                .group_by(*index, \"group\")\n",
    "                .agg(pl.mean(\"data\"))\n",
    "                .with_columns(pl.col(\"group\").replace(group_indices).cast(pl.Int64))\n",
    "                .rename({\"group\": \"roi\"}),\n",
    "            ],\n",
    "        )\n",
    "        .join(atlas_md.rename({\"index\": \"roi\"}), on=\"roi\")\n",
    "        .group_by(*index, \"label\")\n",
    "        .agg(\n",
    "            pl.col(\n",
    "                \"region\",\n",
    "                \"hierarchy\",\n",
    "            ).first(),\n",
    "            pl.col(\"data\").mean(),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sessions = pl.col(\"session\").unique().len().over(\"subject\")\n",
    "\n",
    "\n",
    "def all_sessions(da, hx):\n",
    "    return (\n",
    "        prepare_wm_rois(\n",
    "            da.to_dataset(name=\"data\")\n",
    "            .to_dataframe()\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .pipe(pl.from_pandas),\n",
    "            [\"subject\", \"session\", \"desc\"],\n",
    "        )\n",
    "        .join(hx, on=[\"subject\", \"session\"])\n",
    "        .with_columns(num_sessions=num_sessions)\n",
    "    )\n",
    "\n",
    "\n",
    "topsy_df = all_sessions(\n",
    "    topsy_wm_sampled,\n",
    "    topsy.metadata.filter(\n",
    "        pl.col(\"group\").is_in([\"FEP\", \"HC\"]), pl.col(\"session\").cast(int) < 3\n",
    "    ),\n",
    ")\n",
    "jhp_df = all_sessions(\n",
    "    jhp_wm_sampled,\n",
    "    jhp.metadata.filter(pl.col(\"group\").is_in([\"Patient\", \"HC\"])),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter = so.Jitter(seed=3009)\n",
    "fig = plt.figure(figsize=(8, 10), layout=\"constrained\")\n",
    "axs = fig.subplots(4, 2)\n",
    "\n",
    "variables = np.array([\"FA\", \"MD\", \"RD\", \"L1\"])\n",
    "dfs = [\n",
    "    topsy_df,\n",
    "    jhp_df,\n",
    "]\n",
    "ses_labels = [TOPSY_SESSIONS, JHP_SESSIONS]\n",
    "orders = [[\"HC\", \"FEP\"], [\"HC\", \"Patient\"]]\n",
    "yscales = [\n",
    "    so.Continuous(),\n",
    "    *([so.Continuous().label(like=lambda x, _: f\"{x*1000:.2f}\")] * 3)\n",
    "]\n",
    "units = [\n",
    "    \"\",\n",
    "    *([r\"$\\frac{nm^2}{ms}$\"] * 3)\n",
    "]\n",
    "\n",
    "labels = {\n",
    "    \"PANSSP\": \"PANSS8-P\",\n",
    "    \"PANSSN\": \"PANSS8-N\",\n",
    "    \"sans\": \"SANS\",\n",
    "    \"saps\": \"SAPS\",\n",
    "}\n",
    "\n",
    "for x, y in np.ndindex(4, 2):\n",
    "    variable = variables[x]\n",
    "    label = labels.get(variable, variable)\n",
    "    labely  = f\"{label} ({units[x]})\" if units[x] else label\n",
    "    df = dfs[y]\n",
    "    ax = axs[x, y]\n",
    "    num_sessions = pl.col(\"session\").unique().len().over(\"subject\")\n",
    "    (\n",
    "        so.Plot(\n",
    "            df.filter(\n",
    "                pl.col.label == \"WM\", pl.col.desc == variable, pl.col.num_sessions > 1\n",
    "            )\n",
    "            .with_columns(pl.col.session.cast(int))\n",
    "            .to_pandas(),\n",
    "            x=\"session\",\n",
    "            y=\"data\",\n",
    "            group=\"subject\",\n",
    "            color=\"group\",\n",
    "        )\n",
    "        # .add(so.Line(linestyle=\"dashed\", linewidth=0.5, alpha=0.5), jitter, legend=False)\n",
    "        .add(so.Line(linewidth=2), MLEFit(), legend=False)\n",
    "        .add(so.Band(), Lme4CI(nsims=500), legend=False)\n",
    "        .add(so.Dot(edgewidth=0, alpha=0.5, fill=None), jitter, legend=False)\n",
    "        .scale(\n",
    "            x=so.Continuous().tick(at=[1, 2, 3, 4]).label(like=ses_labels[y].get),\n",
    "            y=yscales[x],\n",
    "            color=so.Nominal(order=orders[y])\n",
    "        )\n",
    "        .label(y=None if y > 0 else labely, x=None if x < 3 else \"Session\")\n",
    "        .on(ax)\n",
    "        .plot()\n",
    "    )\n",
    "axs[0, 0].set_title(\"TOPSY\", **Styles.col_title)\n",
    "axs[0, 1].set_title(\"JHP\", **Styles.col_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-longt\n",
    "cell-offset: -1\n",
    "\n",
    "---\n",
    "Global longitudinal changes of white matter microstructure in early schizophrenia patients. Trendlines show a linear fixed effect model of parameter against session with random intercepts fit for every subject. Shaded bands show a 95% CI computed with parametric bootstrapping resampling residuals and random effects 500 times. No significant differences were found between the slopes of HCs and patients in either dataset for any of the parameters measured. In the JHP sample, fitting random slopes to each subject did not significantly improve the fit of the model (not tested in TOPSY because each subject had only two time points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations with Symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sessions(da, hx):\n",
    "    return prepare_wm_rois(\n",
    "        pl.from_pandas(da.mean(\"session\").to_dataframe(name=\"data\").reset_index()),\n",
    "        [\"subject\", \"desc\"]\n",
    "    ).join(hx, on=\"subject\")\n",
    "\n",
    "\n",
    "topsy_df = avg_sessions(topsy_wm_sampled, topsy_hx)\n",
    "jhp_df = avg_sessions(jhp_wm_sampled, jhp_hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _1tail(pval, stat, desc, param):\n",
    "    val = 1\n",
    "    if desc in {\"FA\", \"thickness\"}:\n",
    "        val *= -1\n",
    "    if \"recovery\" in param:\n",
    "        val *= -1\n",
    "    val *= np.sign(stat)\n",
    "    return (min(0, val) * -1) + (pval * val / 2)\n",
    "\n",
    "\n",
    "def do_stats(col):\n",
    "    def inner(data):\n",
    "        df = data.to_pandas().apply(pd.Series)\n",
    "        model = smf.ols(\n",
    "            f\"data ~ {col} + age + sex\", data=df\n",
    "        ).fit()\n",
    "\n",
    "        token = itx.one(n for n in model.model.exog_names if col in n)\n",
    "        contr = model.t_test(token)\n",
    "        return {\n",
    "            \"intercept\": model.params.loc[\"Intercept\"],\n",
    "            \"beta\": model.params.loc[token],\n",
    "            \"pval\": _1tail(contr.pvalue, contr.statistic, data[0][\"desc\"], col),\n",
    "            \"statistic\": contr.statistic,\n",
    "            \"nobs\": model.nobs,\n",
    "            \"df_model\": model.df_model,\n",
    "            \"df_resid\": model.df_resid,\n",
    "        }\n",
    "\n",
    "    dtype = pl.Struct(\n",
    "        {\n",
    "            \"intercept\": pl.Float64,\n",
    "            \"beta\": pl.Float64,\n",
    "            \"pval\": pl.Float64,\n",
    "            \"statistic\": pl.Float64,\n",
    "            \"nobs\": pl.Float64,\n",
    "            \"df_model\": pl.Float64,\n",
    "            \"df_resid\": pl.Float64,\n",
    "        }\n",
    "    )\n",
    "    return (\n",
    "        pl.struct(\"desc\", \"data\", col, \"age\", \"sex\")\n",
    "        .map_elements(inner, return_dtype=dtype)\n",
    "        .alias(f\"{col}_stats\")\n",
    "    )\n",
    "\n",
    "\n",
    "def pearsonr(col):\n",
    "    def inner(data):\n",
    "        result = scs.pearsonr(\n",
    "            np.asarray(data.struct[col]), np.asarray(data.struct[\"data\"])\n",
    "        )\n",
    "        return result.statistic\n",
    "\n",
    "    return (\n",
    "        pl.struct(\"data\", col)\n",
    "        .filter(~pl.col(col).is_null())\n",
    "        .map_elements(inner, return_dtype=pl.Float64)\n",
    "        .alias(f\"{col}_pearsonr\")\n",
    "    )\n",
    "\n",
    "\n",
    "def get_pvals(col):\n",
    "    return do_stats(col).name.prefix_fields(f\"{col}_\")  # .struct[f\"{col}_pval\"]\n",
    "\n",
    "\n",
    "def get_all_stats(df, scores, features):\n",
    "    return (\n",
    "        df.filter(pl.col(\"num_sessions\") > 1)\n",
    "        .group_by(\"label\", \"desc\")\n",
    "        .agg(\n",
    "            *(\n",
    "                do_stats(f\"{score}_{suffix}\")\n",
    "                for score, suffix in it.product(scores, features)\n",
    "            ),\n",
    "            *(\n",
    "                pearsonr(f\"{score}_{suffix}\")\n",
    "                for score, suffix in it.product(scores, features)\n",
    "            ),\n",
    "            pl.first(\"hierarchy\"),\n",
    "        )\n",
    "        .melt([\"label\", \"desc\", \"hierarchy\"], cs.matches(\".*_stats\"), \"param\", \"stats\")\n",
    "        .with_columns(\n",
    "            pl.col(\"param\").str.split(\"_\").list.to_struct(fields=[\"score\", \"feature\"])\n",
    "        )\n",
    "        .unnest(\"param\", \"stats\")\n",
    "        .with_columns(\n",
    "            pl.col(\"pval\")\n",
    "            .map_elements(\n",
    "                lambda x: pl.Series(scs.false_discovery_control(x)),\n",
    "                return_dtype=pl.List(pl.Float64),\n",
    "            )\n",
    "            .over(\"hierarchy\", \"desc\", \"score\", \"feature\")\n",
    "            .name.suffix(\"corr\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "topsy_stats = get_all_stats(\n",
    "    topsy_df,\n",
    "    [\"PANSSP\", \"PANSSN\"],\n",
    "    [\"recovery\"],\n",
    "    # The rest are not significant\n",
    "    # [\"baseline\", \"mean\", \"slope\", \"intercept\", \"recovery\"],\n",
    ")\n",
    "jhp_stats = get_all_stats(\n",
    "    jhp_df,\n",
    "    [\"saps\", \"sans\"],\n",
    "    [\"baseline\", \"mean\", \"intercept\"],\n",
    "    # The rest are not significant\n",
    "    # [\"baseline\", \"mean\", \"slope\", \"intercept\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = (\n",
    "    jhp_stats.filter(pl.col(\"pvalcorr\") < 0.05)\n",
    "    # .with_columns(parameter=pl.concat_str(\"score\", \"feature\", separator=\"_\"))\n",
    "    .join(\n",
    "        # atlas_md.rename({\"index\": \"roi\"}),\n",
    "        atlas_md.group_by(\"label\").agg(pl.first(\"region\")),\n",
    "        on=\"label\",\n",
    "    )\n",
    "    .pivot(\n",
    "        values=\"pvalcorr\",\n",
    "        index=[\"region\", \"desc\", \"hierarchy\", \"feature\"],\n",
    "        columns=\"score\",\n",
    "    )\n",
    ")\n",
    "# sig.write_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig.write_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df.filter(\n",
    "    pl.col(\"num_sessions\") > 1,\n",
    "    pl.col(\"label\") == \"WM\",\n",
    "    pl.col(\"desc\") == \"L1\",\n",
    ").group_by(\"label\", \"subject\").agg(pl.col(\"*\").exclude(\"data\").first(), pl.col(\"data\").mean())\n",
    "lm1 = smf.ols(\"data ~ Q('PANSSN_recovery')\", data=df_r.to_pandas()).fit()\n",
    "lm2 = smf.ols(\"data ~ Q('PANSSN_recovery') + age\", data=df_r.to_pandas()).fit()\n",
    "lm2.compare_f_test(lm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 10), layout=\"constrained\")\n",
    "axs = fig.subfigures(4, 1)\n",
    "\n",
    "variables = np.array([\"FA\", \"MD\", \"RD\", \"L1\"])\n",
    "yscales = [\n",
    "    so.Continuous(),\n",
    "    *([so.Continuous().label(like=lambda x, _: f\"{x*1000:.2f}\")] * 3),\n",
    "]\n",
    "units = [\"\", *([r\"$\\frac{nm^2}{ms}$\"] * 3)]\n",
    "\n",
    "labels = {\n",
    "    \"PANSSP\": \"PANSS8-P\",\n",
    "    \"PANSSN\": \"PANSS8-N\",\n",
    "    \"sans\": \"SANS\",\n",
    "    \"saps\": \"SAPS\",\n",
    "}\n",
    "\n",
    "for y, x in np.ndindex(4, 1):\n",
    "    variable = variables[y]\n",
    "    label = labels.get(variable, variable)\n",
    "    labely = f\"{label} ({units[y]})\" if units[y] else label\n",
    "    ax = axs[y]\n",
    "    # num_sessions = pl.col(\"session\").unique().len().over(\"subject\")\n",
    "    (\n",
    "        so.Plot(\n",
    "            jhp_df.filter(pl.col(\"hierarchy\") < 2, pl.col.desc == variable)\n",
    "            .join(\n",
    "                jhp_stats.filter(\n",
    "                    pl.col.desc == variable, feature=\"intercept\", score=\"sans\"\n",
    "                )[[\"label\", \"pvalcorr\", \"desc\"]],\n",
    "                on=\"label\",\n",
    "            )\n",
    "            .with_columns(sig=pl.col.pvalcorr < 0.05),\n",
    "            y=\"data\",\n",
    "            x=\"sans_intercept\",\n",
    "        )\n",
    "        .facet(\n",
    "            col=\"region\",\n",
    "            order=[\"White Matter\", \"Core White Matter\", \"Peripheral White Matter\"],\n",
    "        )\n",
    "        .share(y=False)\n",
    "        .add(so.Dot(color=\"#555555\"))\n",
    "        .add(so.Line(), so.PolyFit(1))\n",
    "        .add(so.Band(), PolyCI(ci=95), legend=False)\n",
    "        .add(\n",
    "            so.Text({\"ha\": \"right\" if variable == \"FA\" else \"left\"}),\n",
    "            PearsonrAnnot(\"upper right\" if variable == \"FA\" else None),\n",
    "        )\n",
    "        .label(\n",
    "            title=\"\" if y > 0 else None, x=None if y < 3 else \"SANS Intercept\", y=labely\n",
    "        )\n",
    "        .scale(y=yscales[y], color=[\"#88c\", \"#555\"], )\n",
    "        .on(ax)\n",
    "        .plot()\n",
    "    )\n",
    "    if y == 0:\n",
    "        for i in [2, 3]:\n",
    "            ax.get_children()[i].get_children()[2].set_facecolor((0, 0, 0, 0.2))\n",
    "            ax.get_children()[i].get_children()[1].set_color((0, 0, 0, 0.8))\n",
    "            ax.get_children()[i].get_children()[1].set_linestyle(\":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-jhp-roi\n",
    "cell-offset: -1\n",
    "\n",
    "---\n",
    "Correlation between microstructural parameters and SANS intercept. Microstructural measurements are averaged across all sessions for each subject. The SANS intercept was computed using a first order linear model for each subject, with the baseline scan as time 0. Shaded bands show 95% CI computed with nonparametric bootstrap paired resampling with 10,000 permutations. Relationships were tested with a linear model with age and sex and covariates. Solid lines represent statistically significant relationships, dashed lines are nonsignificant. T-values and P-values are shown in @tbl-XXX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(ax.get_children()[2])\n",
    "ax.get_children()[2].get_children()[2].get_facecolor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jhp_df.filter(pl.col(\"hierarchy\") < 2, pl.col.desc == variable)\n",
    "    .join(\n",
    "        jhp_stats.filter(\n",
    "            pl.col.desc == variable, feature=\"intercept\", score=\"sans\"\n",
    "        )[[\"label\", \"pvalcorr\", \"desc\"]],\n",
    "        on=\"label\",\n",
    "    )\n",
    "    .with_columns(sig=pl.col.pvalcorr < 0.05)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-jhp-rois\n",
    "cell-offset: -1\n",
    "\n",
    "---\n",
    "Correlations between microstructural measures and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of other regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "img = nb.load(jhp.layout.get(suffix=\"skeletonized\", desc=\"FA\")[0])\n",
    "skeleton_mask = binary_dilation(img.get_fdata() > 0)\n",
    "\n",
    "jhu_atlas = np.where(\n",
    "    skeleton_mask,\n",
    "    nb.load(\"../jhp/derivatives/atlases/atlas.nii.gz\").get_fdata(),\n",
    "    0,\n",
    ")\n",
    "lobe_atlas = np.where(\n",
    "    img.get_fdata() > 0, nb.load(\"../jhp/derivatives/atlases/lobe-atlas.nii.gz\").get_fdata(), 0\n",
    ")\n",
    "# core_mask = (jhu_atlas > 0).astype(int)\n",
    "# periph_mask = ((lobe_atlas > 0) & (jhu_atlas == 0)).astype(int)\n",
    "lobe_mask = np.where(jhu_atlas == 0, lobe_atlas, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level2_atlas():\n",
    "    tract_name_to_id = dict(zip(*atlas_md.filter(group=\"core\")[[\"name\", \"index\"]]))\n",
    "    tract_id, jhu_id = atlas_md.filter(\n",
    "        pl.col.hierarchy == 3, ~pl.col.group.is_in({\"unclassified\", \"cerebellar\"})\n",
    "    ).select(\n",
    "        pl.col.group.replace(tract_name_to_id).cast(int),\n",
    "        pl.col.atlas_id,\n",
    "    )\n",
    "    atlas_vals = np.zeros(jhu_atlas.max().astype(int) + 1)\n",
    "    np.put(atlas_vals, jhu_id, tract_id)\n",
    "    return np.asarray(lobe_mask + atlas_vals[jhu_atlas.astype(int)], dtype=int)\n",
    "    \n",
    "def project_level3(df):\n",
    "    atlas_ids, stats = atlas_md.join(df, on=\"label\").filter(\n",
    "        pl.col.pvalcorr < 0.05,\n",
    "        pl.col.hierarchy == 3,\n",
    "    )[[\"atlas_id\", \"statistic\"]]\n",
    "    atlas_vals = np.zeros(jhu_atlas.max().astype(int) + 1)\n",
    "    np.put(atlas_vals, atlas_ids, stats)\n",
    "    return atlas_vals[jhu_atlas.astype(int)]\n",
    "\n",
    "\n",
    "def project_level2(df):\n",
    "    atlas_ids, stats = atlas_md.join(df, on=\"label\").filter(\n",
    "        pl.col.pvalcorr < 0.05,\n",
    "        pl.col.hierarchy == 2,\n",
    "    )[[\"index\", \"statistic\"]]\n",
    "    atlas = get_level2_atlas()\n",
    "    atlas_vals = np.zeros(atlas.max() + 1)\n",
    "    np.put(atlas_vals, atlas_ids, stats)\n",
    "\n",
    "    return atlas_vals[atlas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = jhp_stats.filter(\n",
    "    pl.col.pvalcorr < 0.05,\n",
    "    pl.col.hierarchy.is_in([2, 3]),\n",
    "    pl.col.feature == \"intercept\",\n",
    ").select(min=pl.min(\"statistic\"), max=pl.max(\"statistic\"))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8), facecolor=\"black\")\n",
    "bg = \"../jhp/derivatives/tpl-fa/tpl-study/tpl-study_FA.nii.gz\"\n",
    "\n",
    "descs = [\"MD\", \"RD\", \"L1\"]\n",
    "panel_labels = [\"A\", \"B\"]\n",
    "\n",
    "*panels, gutter = fig.subfigures(3, 1, height_ratios=[10, 10, 0.5])\n",
    "panels[0].suptitle(\n",
    "    \"Peripheral and Core Groups\", **{**Styles.col_title, \"color\": \"#ffffff\"}\n",
    ")\n",
    "panels[1].suptitle(\"JHU ROIs\", **{**Styles.col_title, \"color\": \"#ffffff\"})\n",
    "for i, project in enumerate([project_level2, project_level3]):\n",
    "    panel = panels[i]\n",
    "    panel.text(\n",
    "        0.1,\n",
    "        0.95,\n",
    "        panel_labels[i],\n",
    "        **(Styles.panel_label | {\"color\": \"white\"}),\n",
    "    )\n",
    "    axs = panel.subplots(3, 1)\n",
    "\n",
    "    for y in range(3):\n",
    "        if y == 0:\n",
    "            axs[y].text(0, 1, \"L\", color=\"white\")\n",
    "            axs[y].text(1, 1, \"R\", color=\"white\", ha=\"right\")\n",
    "        param_map = nb.Nifti1Image(\n",
    "            project(jhp_stats.filter(desc=descs[y], feature=\"intercept\")),\n",
    "            img.affine,\n",
    "            img.header,\n",
    "        )\n",
    "        plotting.plot_stat_map(\n",
    "            param_map,\n",
    "            bg,\n",
    "            cut_coords=np.r_[1:45:7j],\n",
    "            resampling_interpolation=\"nearest\",\n",
    "            display_mode=\"z\",\n",
    "            cmap=\"autumn\",\n",
    "            symmetric_cbar=False,\n",
    "            vmin=vmin[0],\n",
    "            vmax=vmax[0],\n",
    "            annotate=False,\n",
    "            colorbar=False,\n",
    "            axes=axs[y],\n",
    "            figure=panel,\n",
    "        )\n",
    "        axs[y].axis(\"on\")\n",
    "        axs[y].get_yaxis().set_ticks([])\n",
    "        axs[y].get_xaxis().set_visible(False)\n",
    "        axs[y].set_ylabel(\n",
    "            descs[y],\n",
    "            **{\n",
    "                **Styles.row_title,\n",
    "                \"color\": \"#ffffff\",\n",
    "                \"ha\": \"center\",\n",
    "                \"fontweight\": \"bold\",\n",
    "            },\n",
    "        )\n",
    "guttergrid = gutter.add_gridspec(1, 3, width_ratios=[10, 80, 10])\n",
    "cbar = gutter.add_subplot(guttergrid[1])\n",
    "cb = add_colorbar(\n",
    "    vmin, vmax, ax=cbar, cmap=\"autumn\", orientation=\"horizontal\", outline=False\n",
    ")\n",
    "cbar.xaxis.label.set_color(\"white\")\n",
    "cbar.tick_params(axis=\"x\", colors=\"white\", labelsize=10)\n",
    "cbar.set_xlabel(\"T-value\", color=\"white\", size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-jhp-heatmap\n",
    "cell-offset: -1\n",
    "\n",
    "---\n",
    "Correlations between microstructural parameters and SANS intercept. Microstructural measures and SANS intercpets were computed as in @fig-jhp-roi. Relationships were tested with a linear model with age and sex and covariates. Significant ROIs are coloured according to their T-value. A and B show two nested hierarchical layers, with B at a finer resolution. Comparisons within each layer were corrected for multiple comparisons using FDR. T-values and P-values are shown in @tbl-XXX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPSY correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = topsy_stats.filter(\n",
    "    pl.col.pvalcorr < 0.05,\n",
    "    pl.col.hierarchy.is_in([2, 3]),\n",
    "    pl.col.feature == \"recovery\",\n",
    ").select(min=pl.min(\"statistic\"), max=pl.max(\"statistic\"))\n",
    "param_map = nb.Nifti1Image(\n",
    "    project_level2(topsy_stats.filter(feature=\"recovery\", desc=\"FA\", score=\"PANSSN\")),\n",
    "    img.affine,\n",
    "    img.header,\n",
    ")\n",
    "bg = \"../jhp/derivatives/tpl-fa/tpl-study/tpl-study_FA.nii.gz\"\n",
    "cuts = np.array([[23, 30], [37, 45]])\n",
    "imgs = np.zeros((2, 2), dtype=object)\n",
    "for y, x in np.ndindex(2, 2):\n",
    "    fig = plt.figure(figsize=(5, 5), facecolor=\"black\")\n",
    "    ax = fig.subplots(1, 1)\n",
    "    plotting.plot_stat_map(\n",
    "        param_map,\n",
    "        bg,\n",
    "        cut_coords=[cuts[y, x]],\n",
    "        resampling_interpolation=\"nearest\",\n",
    "        display_mode=\"z\",\n",
    "        cmap=\"autumn\",\n",
    "        symmetric_cbar=False,\n",
    "        vmin=vmin[0],\n",
    "        vmax=vmax[0],\n",
    "        annotate=False,\n",
    "        colorbar=False,\n",
    "        axes=ax,\n",
    "    )\n",
    "    imgs[y, x] = fig_to_numpy(fig)\n",
    "    plt.close()\n",
    "topsy_tmap = np.vstack([np.hstack([a[150:1300, 300:1200] for a in r]) for r in imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6), layout=\"constrained\")\n",
    "grid = fig.add_gridspec(3, 3)\n",
    "\n",
    "slots = [\n",
    "    grid[0, 0],\n",
    "    grid[0, 1],\n",
    "    grid[0, 2],\n",
    "    grid[1, 0],\n",
    "    grid[2, 0],\n",
    "]\n",
    "\n",
    "sig_topsy = topsy_df.join(\n",
    "    topsy_stats[[\"desc\", \"label\", \"pvalcorr\"]], on=[\"label\", \"desc\"]\n",
    ").filter(pl.col.pvalcorr < 0.05, pl.col.num_sessions > 1)\n",
    "\n",
    "regions = (\n",
    "    sig_topsy.group_by(\"region\")\n",
    "    .agg(pl.first(\"hierarchy\"))\n",
    "    .sort(\"hierarchy\", \"region\")[\"region\"]\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "labels = {\n",
    "    \"PANSSP\": \"PANSS8-P\",\n",
    "    \"PANSSN\": \"PANSS8-N\",\n",
    "}\n",
    "\n",
    "panels = [\"A\", \"B\", None, \"C\", None]\n",
    "\n",
    "for i in range(5):\n",
    "    region = regions[i]\n",
    "    ax = fig.add_subplot(slots[i])\n",
    "    ax.set_title(region)\n",
    "    ax.set_xticks([False, True], labels=[\">3\", \"3\"])\n",
    "    if (panel := panels[i]) is not None:\n",
    "        ax.text(\n",
    "            -0.25,\n",
    "            1,\n",
    "            panel,\n",
    "            transform=ax.transAxes,\n",
    "            **Styles.panel_label,\n",
    "        )\n",
    "\n",
    "    comparison_plot(\n",
    "        sig_topsy.filter(region=region), x=\"PANSSN_recovery\", y=\"data\", ax=ax\n",
    "    )\n",
    "    if i in {4, 1, 2}:\n",
    "        ax.set_xlabel(\"Follow-up PANSS8-N Score\", size=10)\n",
    "    else:\n",
    "        ax.set(xlabel=None)\n",
    "    if i in {0, 3, 4}:\n",
    "        ax.set_ylabel(\"FA\")\n",
    "    else:\n",
    "        ax.set_ylabel(None)\n",
    "\n",
    "\n",
    "fig.patches.append(\n",
    "    plt.Rectangle(\n",
    "        (0.43, 0.02), 0.57, 0.6, color=\"black\", transform=fig.transFigure, zorder=-1\n",
    "    )\n",
    ")\n",
    "atlas_panel = fig.add_subfigure(grid[1:, 1:])\n",
    "atlas_panel.text(\n",
    "    -0.05,\n",
    "    1,\n",
    "    \"D\",\n",
    "    **Styles.panel_label,\n",
    ")\n",
    "axs = atlas_panel.subplots(1, 2, width_ratios=[15, 1])\n",
    "axs[0].imshow(topsy_tmap)\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].set_position(axs[0].get_position().expanded(1.3, 1.3))\n",
    "axs[0].text(\n",
    "    0, 0.45, \"L\", color=\"white\", size=14, fontweight=\"bold\", transform=axs[0].transAxes\n",
    ")\n",
    "axs[0].text(\n",
    "    1,\n",
    "    0.45,\n",
    "    \"R\",\n",
    "    ha=\"right\",\n",
    "    color=\"white\",\n",
    "    size=14,\n",
    "    fontweight=\"bold\",\n",
    "    transform=axs[0].transAxes,\n",
    ")\n",
    "\n",
    "add_colorbar(vmin, vmax, ax=axs[1], cmap=\"autumn\", outline=False)\n",
    "axs[1].set_ylabel(\"T-value\")\n",
    "axs[1].yaxis.label.set_color(\"white\")\n",
    "axs[1].yaxis.set_major_formatter(FormatStrFormatter(\"%0.02f\"))\n",
    "axs[1].tick_params(axis=\"y\", colors=\"white\", labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-topsy-roi\n",
    "cell-offset: -1\n",
    "\n",
    "---\n",
    "Correlations between microstructural parameters and the PANSS8-N follow-up score. Microstructural measures are computed as in @fig-jhp-roi. Subjects are grouped based on whether their PANSS8-N score at their follow-up session was equal to 3, the lowest possible socre. Relationships were tested with a linear model with age and sex and covariates. All comparisons shown are signficant. A and B and C show ROIs from different nested hierarchical layers at successively higher resolutions. D shows the location of the regions in C with their T-values. Comparisons within each layer were corrected for multiple comparisons using FDR. T-values and P-values are shown in @tbl-XXX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topsy_modelling = BidsLayout(\"../topsy/derivatives/models-v0.1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "@layout_map(dims={\"src\": atlases.bn246[\"Label ID\"], \"dest\": atlases.bn246[\"Label ID\"]}, dtype=int)\n",
    "def load_h5_nbs(file):\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        try:\n",
    "            networks =  f[\"nbs/con_mat\"][:]\n",
    "            # sizes = np.sum(networks.reshape(-1, networks.shape[-1]), axis=0)\n",
    "            # labels = np.argsort(sizes)[::-1] + 1\n",
    "            # return np.sum(networks * labels, axis=-1)\n",
    "            sig =  np.sum(networks, axis=-1)\n",
    "        except IndexError:\n",
    "            sig = 0\n",
    "        return f[\"nbs/test_stat\"][:] * sig\n",
    "\n",
    "\n",
    "descs = [\n",
    "    \"\".join(x)\n",
    "    for x in it.product(\n",
    "        [\"AD\", \"FA\", \"MD\", \"RD\"], [\"p\", \"n\"], [\"intercept\", \"recov\", \"slope\"]\n",
    "    )\n",
    "]\n",
    "topsy_nbs = load_h5_nbs(\n",
    "    topsy_modelling.get(suffix=\"nbs\", label=[\"pos\", \"neg\"], desc=descs), [\"desc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(topsy_nbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (\n",
    "    (topsy_nbs > 0)\n",
    "    .sum([\"src\", \"dest\"])\n",
    "    .to_dataframe(name=\"count\")\n",
    "    .reset_index()\n",
    "    .pipe(pl.from_pandas)\n",
    "    .with_columns(\n",
    "        param=pl.col.desc.str.slice(0, 2),\n",
    "        score=pl.col.desc.str.slice(2, 1).replace({\"n\": \"PANSSN\", \"p\": \"PANSSP\"}),\n",
    "        term=pl.col.desc.str.slice(3),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlases.bn246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colormaps.utils import concat as cmaps_concat\n",
    "\n",
    "plt.switch_backend(\"cairo\")\n",
    "\n",
    "side_title = dict(\n",
    "    x=-0.1,\n",
    "    y=0.5,\n",
    "    rotation=\"vertical\",\n",
    "    rotation_mode=\"anchor\",\n",
    "    size=10,\n",
    "    ha=\"center\",\n",
    "    va=\"bottom\",\n",
    "    color=Styles.Colors.dark[0],\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(5.3, 10))\n",
    "main, gutter = fig.subfigures(1, 2, width_ratios=[5, 0.3])\n",
    "axs = main.subplots(4, 2)\n",
    "params = [\"FA\", \"MD\", \"RD\", \"AD\"]\n",
    "terms = [\"recov\", \"slope\"]\n",
    "labels = {\n",
    "    \"recov\": r\"$\\text{Follow-up PANSS8-N} = 3$\",\n",
    "    \"slope\": r\"$\\text{PANSS8-N Slope}$\",\n",
    "}\n",
    "cms = {1: cmaps.ember.cut(0.4, \"left\"), -1: cmaps.cosmic.cut(0.2, \"left\")}\n",
    "vcms = np.array([[1, -1], *([[-1, 1]] * 3)])\n",
    "max_edge = topsy_nbs.max()\n",
    "for y, x in np.ndindex(4, 2):\n",
    "    ax = axs[y, x]\n",
    "    ax.axis(\"off\")\n",
    "    plot_hierachical_connectome(\n",
    "        topsy_nbs.sel(desc=f\"{params[y]}n{terms[x]}\"),\n",
    "        nodes=atlases.bn246,\n",
    "        ax=ax,\n",
    "        emin=3,\n",
    "        emax=max_edge,\n",
    "        # ecmap=cmaps.vivid,\n",
    "        ecmap=cms[vcms[y, x]],\n",
    "        vcmap=cmaps_concat([cmaps.gray_5.cut(0.4, \"right\")] * 4).discrete(8),\n",
    "        hierarchy=[\"Gyrus\", \"hemisphere\"],\n",
    "    )\n",
    "    if x == 0:\n",
    "        ax.set_title(params[y], **(side_title | {\"size\": 12, \"weight\": \"bold\"}))\n",
    "    if y == 0:\n",
    "        ax.text(\n",
    "            0.5,\n",
    "            1.1,\n",
    "            labels[terms[x]],\n",
    "            color=Styles.Colors.dark[0],\n",
    "            size=10,\n",
    "            ha=\"center\",\n",
    "            transform=ax.transAxes,\n",
    "        )\n",
    "\n",
    "grid = gutter.add_gridspec(6, 1)\n",
    "cbar1 = gutter.add_subplot(grid[1:3])\n",
    "add_colorbar(3, max_edge, cms[1], cbar1, outline=False)\n",
    "cbar1.set_ylabel(\"T-value\", size=10, color=Styles.Colors.dark[0])\n",
    "cbar1.set_title(\n",
    "    \"Positive correlations\",\n",
    "    **side_title,\n",
    ")\n",
    "cbar1.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "\n",
    "cbar2 = gutter.add_subplot(grid[3:5])\n",
    "add_colorbar(3, max_edge, cms[-1], cbar2, outline=False)\n",
    "cbar2.set_ylabel(\"T-value\", size=10, color=Styles.Colors.dark[0])\n",
    "cbar2.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "cbar2.set_title(\n",
    "    \"Negative correlations\",\n",
    "    **side_title,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "label: fig-nbs\n",
    "cell-offset: -1\n",
    "\n",
    "---\n",
    "Networks associated with negative symptoms in the TOPSY dataset. Microstructural measures are averaged across sessions. Values for each connection were measured by sampling along the constituent streamlines. The recovery score is computed as in @fig-topsy-roi. The PANSS8-N slope was computed for each subject by fitting a first-order model to the symptom measurements across sessions. In each network diagram, lines represent connections significantly correlated with the corresponding PANSS8-N derivative measure as determined using NBS (10,000 samples, $T_{thresh}=3$, $p<0.5$). For instance, the top-left diagram represents connections with significantly higher FA in patients a PANSS8-N score of 3 (the lowest possible score) a their follow-up session. Gyral abbreviations are given in @tbl-XXX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
